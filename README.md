# Spec‑Driven AI Development Framework (SDAIDF) for Snowflake
## With Privacy‑Preserving Snowflake Tooling & Test‑Driven Development

**Version:** 3.0  
**Date:** February 18, 2026  
**Author:** Tanay Lodh  

---

## 1. Overview

This document describes the **Agentic AI assisted Snowflake Data Engineering workflow** using **SDAIDF**. The system enables AI‑assisted development of Snowflake objects (tables, views, ETL procedures) with a strong emphasis on **safety, repeatability, and human oversight to plan autonomous development**.

The workflow is driven by five specialized agents, a rich file‑based state, and a set of [Snowflake‑specific MCP tools](https://github.com/Snowflake-Labs/mcp?tab=readme-ov-file). It transforms a high‑level **feature** request into a queue of tested, production‑ready changes, while ensuring that **no production data is ever exposed to the AI** and that every significant action requires human approval.

---

## 2. Core Principles

- **Human‑guided AI** – The AI proposes, the human disposes. All critical decisions (plan approval, fix promotion, destructive operations) require explicit user consent.
- **Pattern control** – The system learns your team’s coding patterns (naming conventions, architecture, security rules) and generates code that matches them from the start.
- **Token efficiency (MVI)** – Only the minimal context necessary for a task is loaded. Context files are small (<200 lines) and loaded on demand.
- **Transparency** – Every agent is an editable markdown file. Every piece of state (task queue, object documentation) is stored in markdown files as well, that can be read, edited, and version‑controlled.
- **Safety by design** – A metadata‑only proxy strips all row data from Snowflake responses. Exclusion rules prevent accidental access to production objects.

---

## 3. Agent Roles

| Agent Name | Responsibility |
|------------|----------------|
| **discovery** | Scans the Snowflake environment, builds the local mirror, and creates per‑object context files (business definitions, lineage, PII flags). |
| **planner** | Takes a user feature description (from `feature.md`), breaks it into discrete tasks with dependencies, generates a task list and per‑task detail files. Also creates a **feature test specification** that describes real‑world business scenarios to validate the entire feature. |
| **orchestrator** | Orchestrates execution: reads the task list, selects the next eligible task (prioritising fixes), performs a staleness check, and invokes the **developer** agent for that task. Continues until all tasks are processed. Once all tasks are complete, invokes the **tester** agent to run the feature test specification. |
| **developer** | Executes a single task: implements the required changes (using Snowflake MCP tools via the proxy) and reports the outcome. On failure, creates a draft fix. **Has no access to the feature test specification** – it works solely from the task detail. |
| **tester** | Executes the feature test specification against the Snowflake environment (via the metadata proxy) after all tasks are completed. Validates that the implemented feature meets the business scenarios defined by the planner. Reports pass/fail and detailed logs. |

*Note: The **orchestrator** is the “parent” coordinator; the **developer** and **tester** are short‑lived subagents invoked for specific purposes.*

---

## 4. File Structure

All state is stored under the project’s `agent/` directory, which should be version‑controlled.

```
project-root/
├── agents/                     # Editable agent definitions (markdown)
│   ├── discovery.md
│   ├── planner.md
│   ├── orchestrator.md
│   ├── developer.md
│   └── tester.md
├── src/                     # Mirrors Snowflake object hierarchy
│   └── {DB}/
│       └── {SCHEMA}/
│           ├── {TYPE}/
│           │   ├── {OBJECT}.sql       # DDL and path to corresponding {OBJECT}.md as a comment
│           └── ...
├── context/                     # Environmental knowledge base
│   ├── feature.md                # Current feature description (user provided)
│   ├── environment.md           # Global summary (index, team patterns)
│   └── {DB}/
│       └── {SCHEMA}/
│           ├── {TYPE}/
│           │   └── {OBJECT}.md        # Business context, lineage, notes
│           └── ...
├── tasks/
│   ├── tasks.md                 # Task queue (markdown table)
│   ├── details/                  # Per‑task detail files
│   │   ├── TASK-001.md
│   │   ├── TASK-002.md
│   │   └── ...
│   └── draft-fixes/              # Draft fixes awaiting review
│       └── FIX-draft-{timestamp}.md
├── tests/
│   └── feature-{id}-test.md      # Feature test specification (generated by planner)
├── logs/
│   └── event-log.md             # Audit trail of all actions
└── config/
    └── project.yaml              # Project settings (exclusion rules, sync behaviour)
```

---

## 5. Detailed Workflows

### 5.1 Environment Setup (Discovery Agent)

**Trigger:** User runs `opencode --agent discovery` (first time or after environmental changes).

**Steps:**

1. **Read configuration** – Load `project.yaml` for Snowflake connection details and exclusion patterns (e.g., `"PROD.*"`).
2. **Mirror environment** – Using the `snowflake_sync` tool (built on top of Snowflake MCP):
   - Fetch all databases, schemas, and objects that do **not** match exclusion patterns.
   - For each allowed object, create the corresponding file tree under `src/`.
   - Store the current DDL in `src/{DB}/{SCHEMA}/{TYPE}/{OBJECT}.sql`.
3. **Create per‑object context files** – For each object, under `context/{DB}/{SCHEMA}/{TYPE}/` create or update `{OBJECT}.md` with:
   - Basic metadata (columns, types).
   - Data lineage (using discovery tool built on top of Snowflake MCP).
   - Placeholders for business context (to be filled later via conversation).
4. **Build global summary** – Write `agent/context/environment.md` containing:
   - List of all databases/schemas/objects (with links to detail files).
   - Team‑wide coding patterns (from configuration or user input).
   - Any global notes.
5. **Conversational enrichment** – If the agent encounters objects with missing context, it may ask the user questions (e.g., “What is the source system for table `orders`?”) and store the answers in the corresponding `{OBJECT}.md`.
6. **Log all actions** – Append to `event-log.md`.

**Outcome:** A complete, locally stored, and human‑augmented representation of the development Snowflake environment.

---

### 5.2 Feature Planning (Planner Agent)

**Trigger:** User runs `opencode --agent planner @/context/feature.md`.

**Steps:**

1. **Load feature description** – The feature is passed as an argument, read from a user‑editable `feature.md` file.
2. **Discover relevant context** – The agent uses `ContextScout` to identify which objects and patterns are relevant to the feature (based on keywords, object names mentioned, etc.). It loads only the necessary per‑object `.md` files and the global `environment.md`.
3. **Decompose into tasks** – The agent breaks the feature into a sequence of discrete, testable tasks. Each task should represent a single logical change (e.g., “create table X”, “populate table Y”, “add constraint Z”).
4. **Define dependencies** – For each task, determine which other tasks must be completed first. Dependencies are expressed as task IDs.
5. **Generate task detail files** – For each task, create a file under `agent/tasks/details/{ID}.md` with the following structure:

   ```markdown
   ---
   id: TASK-001
   type: dev                # or "fix"
   goal: "Create base table cust_monthly_summary"
   constraints: |
     - Use clustering on customer_id
     - Table must be in the `analytics` schema
   depends_on: []          # IDs of tasks this depends on
   ---
   <!-- Implementation notes and context extracted from environment -->
   The table should have columns:
   - customer_id NUMBER
   - month DATE
   - total_spend NUMBER(10,2)
   ```

   *Note: No embedded tests – testing is handled separately by the feature test specification.*

6. **Create feature test specification** – The planner writes a markdown file under `agent/tests/feature-{id}-test.md` containing realistic business scenarios that validate the entire feature. Example structure:

   ```markdown
   # Feature Test: Monthly Customer Summary

   ## Scenario 1: Basic aggregation
   - Given orders for customer 123 in January 2026 (total $500) and February 2026 (total $300)
   - When the `cust_monthly_summary` table is populated
   - Then rows for customer 123 should show January total = 500, February total = 300

   ## Scenario 2: No orders
   - Given a customer with no orders
   - Then no row should appear for that customer in the summary table

   ## Scenario 3: Edge case – large volume
   - (Describe a high‑volume test to ensure performance)
   ```

   The test specification is meant to be executed by the **tester** agent, which will translate these scenarios into SQL assertions or data validation steps.

7. **Update task list** – Append rows to `agent/tasks/tasks.md`:

   ```
   | ID       | Type | Status    | Dependencies | Description                     |
   |----------|------|-----------|--------------|---------------------------------|
   | TASK-001 | dev  | pending   |              | Create base table               |
   | TASK-002 | dev  | pending   | TASK-001     | Populate with monthly aggregate |
   ```

8. **Present plan to user** – The agent outputs the task list and the test specification summary, then asks for approval. The user may:
   - Approve (proceed to execution).
   - Request modifications (e.g., reorder tasks, adjust dependencies, refine test scenarios).
   - Reject (abort).

**Outcome:** An approved, structured task queue and a corresponding feature test specification.

---

### 5.3 Execution (Orchestrator Agent)

**Trigger:** User runs `opencode --agent orchestrator`. This can be run repeatedly; the agent will process tasks until the queue is empty.

**Orchestrator agent loop:**

1. **Load task list** – Parse `tasks.md` into a list of tasks with their current status.
2. **Select next task**:
   - Filter for tasks with `Status == "pending"`.
   - For each, check dependencies: all listed IDs must have `Status == "completed"`.
   - Among eligible tasks, **prioritise** those with `Type == "fix"` over `dev`. Within each type, respect the order in the table (which the planner sets sensibly).
   - If no eligible task, exit the loop.
3. **Staleness check** – Before invoking the developer, the orchestrator performs a quick check using the MCP `check_staleness` tool:
   - It examines the task’s detail file to identify all Snowflake objects referenced.
   - It queries the remote environment for the last modified timestamp (or a hash of the DDL) of those objects.
   - If any object has changed since the task was planned:
     - Prompt the user: *“Environment has changed for objects used in task {ID}. Re‑plan this task? (y/n/always)”*
     - If “y”, call the planner agent (with a sub‑goal to replan this specific task) and then restart the loop (the task may be replaced).
     - If “n”, mark the task as `blocked` in `tasks.md` (with a note) and continue to the next eligible task.
     - If “always”, update configuration to auto‑replan in the future.
4. **Invoke developer** – Call the developer agent, passing the task ID (e.g., `TASK-001`). The developer runs in a separate process/session.
5. **Process developer result**:
   - **Success**: Update the task’s status to `completed` in `tasks.md`.
   - **Failure**: The developer will have created a **draft fix** file in `agent/tasks/draft-fixes/`. The orchestrator **does not** stop; it continues to the next eligible task (if any).
6. **Repeat** until no more pending tasks with satisfied dependencies exist.
7. **Final step: feature test execution** – After all tasks are completed (i.e., no pending tasks remain), the orchestrator invokes the **tester** agent, passing the path to the feature test specification (`agent/tests/feature-{id}-test.md`).
8. **Process tester result**:
   - **Tests pass**: Log success and optionally notify the user.
   - **Tests fail**: The tester will produce a detailed failure report in `logs/` and possibly create draft fixes for any tasks that need adjustment. (The exact mechanism for translating test failures into fixes is TBD; currently, the tester may simply alert the user, and the user can create new tasks manually or via planner.)
9. **Check for draft fixes** – After tester completes, the orchestrator checks for any new draft fixes (from developer failures or tester‑generated issues) and prints a summary: *“X draft fix(es) awaiting review. Run ‘opencode --agent planner review-drafts’ to review and promote.”*
10. **Exit**.

**Outcome:** All possible tasks have been executed, and the feature has been validated against the test specification. Any failures have been captured as draft fixes for human review.

---

### 5.4 Task Execution (Developer Agent)

**Trigger:** Invoked by the orchestrator with a specific task ID.

**Steps:**

1. **Load task detail** – Read `agent/tasks/details/{ID}.md` and parse its YAML frontmatter and body.
2. **Set up environment** – The developer uses the same MCP tools as other agents, but all Snowflake queries go through the **metadata proxy** (see Section 6). It **does not** have access to the feature test specification.
3. **Implement task** – Based on the goal and constraints, the agent performs the necessary DDL/DML operations through the MCP tools.
4. **Determine outcome**:
   - **Success**: Write a success log to `agent/logs/event-log.md`. Exit with code 0.
   - **Failure**: Capture failure details (error message, what went wrong). Write a detailed failure log to `event-log.md`. **Create a draft fix**:
     - Generate a draft fix file in `agent/tasks/draft-fixes/FIX-draft-{timestamp}.md` with the following content:
       ```yaml
       ---
       original_task: TASK-001
       failure: |
         Error: Insufficient privileges to create table in schema ANALYTICS.
       proposed_fix: |
         Steps:
         1. Verify the role has CREATE TABLE privilege on the ANALYTICS schema.
         2. Either grant the privilege or switch to a role with appropriate rights.
       ---
       ```
     - Do **not** add a fix task to the main queue yet.
     - Exit with code 1.

**Outcome:** The task is either completed successfully, or a draft fix is created for human review.

---

### 5.5 Feature Testing (Tester Agent)

**Trigger:** Invoked by the orchestrator with the path to a feature test specification.

**Steps:**

1. **Load test specification** – Read `agent/tests/feature-{id}-test.md` and parse the business scenarios.
2. **Translate scenarios into executable tests** – The tester converts each scenario into one or more SQL assertions or data validation steps. For example:
   - It may insert test data into a temporary schema, run the feature’s logic, and query results.
   - It uses the metadata proxy to ensure no production data is exposed.
3. **Execute tests** – Run the translated tests against the Snowflake environment.
4. **Record results** – For each test, log pass/fail and any discrepancies.
5. **Determine overall outcome**:
   - **All tests pass**: Write a success log to `event-log.md`. Exit with code 0.
   - **Any test fails**:
     - Capture detailed failure information (which scenario failed, actual vs. expected, error messages).
     - Write a failure report to `agent/logs/feature-test-failure-{timestamp}.log`.
     - Optionally, the tester may generate draft fixes or suggestions for remediation (e.g., “Task TASK-002 did not correctly aggregate data; consider revising the population logic.”). These are stored as draft fixes in `draft-fixes/` with a reference to the test failure.
     - Exit with code 1.

**Outcome:** The feature is validated; failures are documented and may lead to new fix tasks.

---

### 5.6 Draft Fix Review and Promotion

**Trigger:** User runs `opencode --agent planner review-drafts` after being notified.

**Steps:**

1. **List all draft fixes** – The planner agent reads the `draft-fixes/` directory and presents each draft to the user with its content.
2. **For each draft, user chooses**:
   - **Approve** – The planner promotes the draft to a real fix task:
     - Creates a new task ID (e.g., `FIX-001`).
     - Generates a task detail file under `tasks/details/FIX-001.md`, incorporating the proposed fix steps and the original task’s context.
     - Adds a row to `tasks.md` with type `fix`, appropriate dependencies (usually the original task and any others required).
   - **Edit** – The user can modify the proposed fix steps before promotion. The planner opens an editor for the draft content, then promotes as above.
   - **Reject** – The draft is moved to an archive (or deleted).
3. **Log all actions** – Record promotions/rejections in `event-log.md`.

**Outcome:** New fix tasks are added to the queue, ready for execution. The orchestrator will prioritise them in the next run.

---

### 5.7 Handling Blocked Tasks

Tasks may become blocked due to:
- Stale environment (detected during staleness check).
- Dependencies that cannot be satisfied (e.g., a required task was abandoned).

Blocked tasks remain in `tasks.md` with status `blocked` and a note. The user can later:
- Manually resolve the issue (e.g., update environment, replan) and change status back to `pending`.
- Ask the planner agent to replan the blocked task.

---

## 6. Safety and Guardrails

### 6.1 Metadata‑Only Proxy

All SQL queries executed by agents (except test assertions) go through a local proxy that:
- Strips all row data from results, returning only schema, statistics (row count, null counts, distinct counts, min/max), and inferred VARIANT structure as a typescript interface.
- Enforces exclusion rules: any query targeting an object that matches `production_exclusion` patterns returns an error.
- Logs every transformed query to an audit file.

### 6.2 Exclusion Rules

Defined in `project.yaml` as regex patterns (e.g., `"PROD.*"`, `".*_BACKUP"`). These apply to:
- The initial sync (objects matching patterns are **not** mirrored).
- Runtime queries (proxy blocks access).
- Task planning (planner should not generate tasks involving excluded objects).

### 6.3 Approval Gates

- **Plan approval**: User must approve the task list and test specification before any execution begins.
- **Destructive operations**: MCP tools for DROP, ALTER, etc., are configured to require explicit user confirmation (via OpenCode’s `trust` settings) before execution.
- **Draft fix promotion**: Fixes are only added to the queue after human review.
- **Staleness handling**: User decides whether to replan stale tasks.

### 6.4 Audit Logging

All actions are appended to `agent/logs/event-log.md` with timestamps:
- Agent invocations.
- Task status changes.
- Draft fix creation/promotion.
- Test execution results.
- Proxy‑transformed queries (summarised, not raw data).

---

## 7. Alignment with [OpenAgentsControl](https://github.com/darrenhinde/OpenAgentsControl) Principles

| Principle | Implementation |
|-----------|----------------|
| **Pattern Control** | Per‑object context files (`{OBJECT}.md`) encode team patterns. Developer generates code that respects these patterns. |
| **Approval Gates** | Plan approval, draft fix promotion, and tool‑level approvals for destructive operations. |
| **MVI (Token Efficiency)** | Developer loads only the task detail file. Planner loads only relevant object context. Tester loads only the test specification. |
| **Editable Agents** | All agents are markdown files under `agent/agents/`; anyone can edit them. |
| **Team‑Ready** | Entire `agent/` directory can be version‑controlled; new team members inherit the setup. |
| **Model Agnostic** | The framework works with any LLM supported by OpenCode; no vendor lock‑in. |

---

## 8. Example Walkthrough

**Feature:** “Create a monthly customer summary table in the analytics schema.”

1. **User writes feature description** in `agent/context/feature.md`.
2. **User runs planner:**
   ```
   opencode --agent planner @/context/feature.md
   ```
   - Planner discovers relevant tables (`customers`, `orders`) from context.
   - Breaks into tasks:
     - `TASK-001`: Create table `cust_monthly_summary` (with columns, clustering).
     - `TASK-002`: Populate table with aggregation from `orders`.
   - Creates task detail files and `tasks.md`.
   - Creates a feature test specification `tests/feature-001-test.md` with scenarios like:
     - *Given orders for a customer in two months, the summary should show correct totals.*
     - *Given a customer with no orders, no row appears.*
   - Asks user for approval. User approves.

3. **User runs orchestrator:**
   ```
   opencode --agent orchestrator
   ```
   - Orchestrator reads `tasks.md`, sees `TASK-001` pending with no dependencies.
   - Performs staleness check: `customers` and `orders` unchanged → OK.
   - Invokes developer for `TASK-001`.
   - Developer creates table, reports success → orchestrator marks `TASK-001` completed.
   - Next, `TASK-002` now eligible. Developer runs aggregation, reports success → marked completed.
   - No more tasks; orchestrator invokes tester with the test specification.
   - Tester sets up test data, runs scenarios, verifies results. All pass.
   - Orchestrator checks for draft fixes (none) and exits.

4. **User is notified** that the feature is complete and tested.

---

## 9. Conclusion

This updated workflow provides a **safe, repeatable, and transparent** AI‑assisted development environment for Snowflake, with a clear separation between task implementation and feature‑level testing. By decoupling testing into a dedicated agent and a single test specification, the system ensures that the overall business requirement is validated without exposing test details to the developer agent. This aligns with the principles of human oversight, token efficiency, and team‑ready transparency.

All components are designed to be **extensible** – new MCP tools can be added, agent prompts can be tuned, and the file formats can evolve as needed.

---

*This document is the authoritative source for the workflow design. Any changes must be reviewed and reflected here.*
